# 차원 축소 (Dimensionality Reduction)

## 1. 차원 축소의 배경
### 차원의 저주 (Curse of Dimensionality)
* 정의: 변수(차원)가 증가할 때, 데이터를 설명하기 위해 필요한 데이터 양이 기하급수적으로 증가하는 현상
* 문제점:데이터 밀도 급감 (Sparsity): 공간은 넓어지나 데이터는 부족해져 빈 공간이 생김
    *거리 정보 왜곡: 고차원에서는 모든 점 사이의 거리가 비슷해져 변별력이 사라짐
    *과적합 (Overfitting): 불필요한 변수로 인해 모델이 노이즈까지 학습함



### 다중공선성 (Multicollinearity)
* 정의: 독립 변수들 사이에 강한 상관관계가 나타나는 문제
* 영향: 모델의 해석력을 떨어뜨리고 수치적 불안정성을 초래함 (정보의 중복)

---

## 2. 변수 선택 (Feature Selection)
> 기존 변수 중 중요한 것만 골라내는 방법 (Original Features 유지)

### 휴리스틱 탐색법 (Heuristic Search)
1. 전진 선택법 (Forward Selection): 0개에서 시작하여 가장 중요한 변수를 하나씩 추가 (계산 속도 빠름)
2. 후진 소거법 (Backward Elimination): 전체에서 시작하여 가장 의미 없는 변수를 하나씩 제거
3. 단계적 선택법 (Stepwise Selection): 추가와 제거를 반복하며 최적의 부분집합(Subset)을 찾음 (가장 효율적)

### 유전자 알고리즘 (Genetic Algorithm)
* 특징: 생물의 진화 원리(교차, 변이)를 이용해 최적의 조합을 탐색
* 장단점: 해의 질은 가장 우수하나 연산 시간이 매우 오래 걸림

---

## 3. 변수 추출 (Feature Extraction) 
> 기존 변수를 조합하여 새로운 변수를 생성 (Transformation)

### 주요 개념: 개념적 손실 (Conceptual Loss)
* 변수를 섞어서 새로 만들기 때문에, 추출된 변수가 원래 어떤 의미였는지 직관적으로 설명하기 어려움

### 주성분 분석 (PCA, Principal Component Analysis)
* 목적:데이터의 분산(Variance)을 최대한 보존**하는 새로운 축을 찾음
* 수학적 핵심:데이터 센터링: 평균을 0으로 맞추는 전처리 필수
    *고유값(Eigenvalue): 해당 축이 담고 있는 정보량(분산의 크기)
    *고유벡터(Eigenvector): 새로운 축의 방향



### 다차원 척도법 (MDS, Multidimensional Scaling)
* 목적: 개체 간의 거리(비유사성) 정보를 최대한 보존하며 저차원으로 매핑
* 특징: 고차원에서 가까웠던 데이터는 저차원에서도 가깝게 유지되도록 시각화하는 데 강점

---

## 4. 요약 및 비교

### 변수 선택 vs 변수 추출
| 구분 | 변수 선택 (Selection) | 변수 추출 (Extraction) |
| :--- | :--- | :--- |
| **방법** | 중요 변수 선별 (Subset) | 변수 조합 및 생성 (New Var) |
| **장점** | 해석력이 높음 | 정보 보존율이 높음 |
| **단점** | 변수 간 중복 해결 한계 | 해석이 어려움 (Conceptual Loss) |

### PCA vs MDS
| 구분 | PCA | MDS |
| :--- | :--- | :--- |
| **보존 대상** | 고유 분산 (Variance) | 관측치 간 거리 (Distance) |
| **주 목적** | 정보 압축, 노이즈 제거 | 데이터 유사성 시각화 |
